library(bujar)
library(survival)
library(ggplot2)
library(tidyr)
library(dnn)

simulate_stage <- function(seed) {
  set.seed(seed)
  n <- 1000
  Sex <- rbinom(n, 1, 0.5)
  TumorSize <- runif(n, 1, 3)
  BMI <- rnorm(n, mean = 25, sd = 5)
  Age <- rnorm(n, mean = 50, sd = 10)
  
  # True parameters
  beta_0 <- 10
  beta_1 <- 0.4
  beta_2 <- -1
  beta_3 <- -0.4
  beta_4 <- -0.01
  gamma_1 <- 0.05
  gamma_2 <- 1.5
  
  # True Q-values
  TumorSize.trans <- TumorSize^(2.3) - median(TumorSize^(2))
  Q_A_true <- pmax(beta_0 + beta_1 * Sex + beta_2 * TumorSize.trans + beta_3 * log(BMI) + beta_4 * sqrt(Age)
                   + gamma_1 + gamma_2 * TumorSize.trans, 0.001)
  Q_B_true <- pmax(beta_0 + beta_1 * Sex + beta_2 * TumorSize.trans + beta_3 * log(BMI) + beta_4 * sqrt(Age)
                   , 0.001)
  epsilon <- rnorm(n)
  A <- rbinom(n, 1, 0.5)
  T_true <- ifelse(A == 1, Q_A_true, Q_B_true) + epsilon
  T_true <- pmax(T_true, 0.01)
  C <- runif(n, quantile(T_true, 0.2), quantile(T_true, 0.8))
  Y <- pmin(T_true, C)
  delta <- as.numeric(T_true <= C)
  
  df <- data.frame(Sex, TumorSize, BMI, Age, A, T_obs = Y, delta, Q_A_true, Q_B_true)
  df_A <- df[df$A == 1, ]
  df_B <- df[df$A == 0, ]
  x_A <- as.matrix(df_A[, c("Sex", "TumorSize", "BMI", "Age")])
  x_B <- as.matrix(df_B[, c("Sex", "TumorSize", "BMI", "Age")])
  x_all <- as.matrix(df[, c("Sex", "TumorSize", "BMI", "Age")])
  
  fit_A_bj <- bujar(log(df_A$T_obs), df_A$delta, x_A, learner = "linear.regression", tuning = FALSE)
  fit_B_bj <- bujar(log(df_B$T_obs), df_B$delta, x_B, learner = "linear.regression", tuning = FALSE)
  Q_A_bj <- exp(predict(fit_A_bj, newx = x_all))
  Q_B_bj <- exp(predict(fit_B_bj, newx = x_all))
  
  fit_A_bjls <- bujar(log(df_A$T_obs), df_A$delta, x_A, twin = TRUE, mstop = 1000, mstop2 = 100, cv = FALSE)
  fit_B_bjls <- bujar(log(df_B$T_obs), df_B$delta, x_B, twin = TRUE, mstop = 1000, mstop2 = 100, cv = FALSE)
  Q_A_bjls <- exp(predict(fit_A_bjls, newx = x_all))
  Q_B_bjls <- exp(predict(fit_B_bjls, newx = x_all))
  
  fit_A_bjtree <- bujar(log(df_A$T_obs), df_A$delta, x_A, learner = "tree", tuning = TRUE, degree = 2, mstop = 100, cv = FALSE)
  fit_B_bjtree <- bujar(log(df_B$T_obs), df_B$delta, x_B, learner = "tree", tuning = TRUE, degree = 2, mstop = 100, cv = FALSE)
  Q_A_bjtree <- exp(predict(fit_A_bjtree, newx = x_all))
  Q_B_bjtree <- exp(predict(fit_B_bjtree, newx = x_all))
  
  # Cox
  fit_A_cox <- coxph(Surv(T_obs, delta) ~ Sex + TumorSize, data = df_A)
  fit_B_cox <- coxph(Surv(T_obs, delta) ~ Sex + TumorSize, data = df_B)
  lp_A <- predict(fit_A_cox, newdata = df, type = "lp")
  lp_B <- predict(fit_B_cox, newdata = df, type = "lp")
  base_A <- basehaz(fit_A_cox, centered = FALSE)
  base_B <- basehaz(fit_B_cox, centered = FALSE)
  compute_surv <- function(lp, base) {
    sapply(lp, function(lpi) sum(diff(c(0, base$time)) * exp(-base$hazard * exp(lpi))))
  }
  Q_A_cox <- compute_surv(lp_A, base_A)
  Q_B_cox <- compute_surv(lp_B, base_B)
  
  list(
    A = A,
    Q_A_true = Q_A_true, Q_B_true = Q_B_true,
    Q_A_bj = Q_A_bj, Q_B_bj = Q_B_bj,
    Q_A_bjls = Q_A_bjls, Q_B_bjls = Q_B_bjls,
    Q_A_bjtree = Q_A_bjtree, Q_B_bjtree = Q_B_bjtree,
    Q_A_cox = Q_A_cox, Q_B_cox = Q_B_cox
  )
}

# Run stage 1 and stage 2
stage1 <- simulate_stage(1111)
stage2 <- simulate_stage(11)

# Combine stage results
combo <- paste0(ifelse(stage1$A == 1, "A", "B"), ifelse(stage2$A == 1, "A", "B"))
df_cum <- data.frame(
  combo = combo,
  True = ifelse(stage1$A == 1, stage1$Q_A_true, stage1$Q_B_true) +
    ifelse(stage2$A == 1, stage2$Q_A_true, stage2$Q_B_true),
  BJ = ifelse(stage1$A == 1, stage1$Q_A_bj, stage1$Q_B_bj) +
    ifelse(stage2$A == 1, stage2$Q_A_bj, stage2$Q_B_bj),
  BJLS = ifelse(stage1$A == 1, stage1$Q_A_bjls, stage1$Q_B_bjls) +
    ifelse(stage2$A == 1, stage2$Q_A_bjls, stage2$Q_B_bjls),
  BJTree = ifelse(stage1$A == 1, stage1$Q_A_bjtree, stage1$Q_B_bjtree) +
    ifelse(stage2$A == 1, stage2$Q_A_bjtree, stage2$Q_B_bjtree),
  Cox = ifelse(stage1$A == 1, stage1$Q_A_cox, stage1$Q_B_cox) +
    ifelse(stage2$A == 1, stage2$Q_A_cox, stage2$Q_B_cox)
)

# Convert to long format
df_long <- pivot_longer(df_cum, cols = -combo, names_to = "Method", values_to = "Cumulative_Q")
df_long$Method <- factor(df_long$Method,
                         levels = c("True", "BJ", "BJLS", "BJTree", "Cox"),
                         labels = c("True", "BJ", "BJ-LS", "BJ-Tree", "Cox"))

# Color palette
colors <- c("True" = "#000000",
            "BJ" = "#000066",
            "BJ-LS" = "#3366CC",
            "BJ-Tree" = "#CCE5FF",
            "Cox" = "white")

# Plot boxplot
ggplot(df_long, aes(x = combo, y = Cumulative_Q, fill = Method)) +
  geom_boxplot(alpha = 0.7, position = position_dodge(width = 0.8)) +
  labs(
    title = "True vs Estimated Q-values",
    x = "Treatment Combination (AA, AB, BA, BB)",
    y = "Cumulative Q-value",
    fill = "Method"
  ) +
  scale_fill_manual(values = colors) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 16),
    axis.text.y = element_text(size = 16),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold"),
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
    legend.title = element_text(size = 16),
    legend.text = element_text(size = 14)
  ) +
  ylim(0, 200)

# Accuracy vectors for each method
n <- 500
n_sim <- 100
acc_bj_cum <- numeric(n_sim)
acc_bjls_cum <- numeric(n_sim)
acc_bjtree_cum <- numeric(n_sim)
acc_cox_cum <- numeric(n_sim)

for (sim in 1:n_sim) {
  cat("Simulation:", sim, "\n")
  
  # Repeat twice and take average decision correctness over both repetitions
  decisions <- list()
  true_opts <- list()
  
  for (rep in 1:2) {
    # Data generation
    Sex <- rbinom(n, 1, 0.5)
    TumorSize <- runif(n, 1, 3)
    BMI <- rnorm(n, mean = 25, sd = 5)
    Age <- rnorm(n, mean = 50, sd = 10)
    
    # True parameters
    beta_0 <- 10
    beta_1 <- 0.4
    beta_2 <- -1
    beta_3 <- -0.4
    beta_4 <- -0.01
    gamma_1 <- 0.05
    gamma_2 <- 1.3
    
    # True Q-values
    TumorSize.trans <- TumorSize^(2.4) - median(TumorSize^(2.2))
    Q_A_true <- pmax(beta_0 + beta_1 * Sex + beta_2 * TumorSize.trans + beta_3 * log(BMI) + beta_4 * sqrt(Age)
                     + gamma_1 + gamma_2 * TumorSize.trans, 0.001)
    Q_B_true <- pmax(beta_0 + beta_1 * Sex + beta_2 * TumorSize.trans + beta_3 * log(BMI) + beta_4 * sqrt(Age)
                     , 0.001)
    epsilon <- rnorm(n)
    A <- rbinom(n, 1, 0.5)
    T_true <- ifelse(A == 1, Q_A_true, Q_B_true) + epsilon
    T_true <- pmax(T_true, 0.01)
    C <- runif(n, quantile(T_true, 0.2), quantile(T_true, 0.8))
    Y <- pmin(T_true, C)
    delta <- as.numeric(T_true <= C)
    
    df <- data.frame(Sex, TumorSize, BMI, Age, A, T_obs = Y, delta, Q_A_true, Q_B_true)
    df_A <- df[df$A == 1, ]
    df_B <- df[df$A == 0, ]
    
    x_A <- as.matrix(df_A[, c("Sex", "TumorSize", "BMI", "Age")])
    x_B <- as.matrix(df_B[, c("Sex", "TumorSize", "BMI", "Age")])
    x_all <- as.matrix(df[, c("Sex", "TumorSize", "BMI", "Age")])
    
    # True optimal
    true_opt <- ifelse(Q_A_true > Q_B_true, 1, 0)
    true_opts[[rep]] <- true_opt
    
    # --- BJ Linear ---
    fit_A_bj <- bujar(log(df_A$T_obs), df_A$delta, x_A, learner = "linear.regression", tuning = FALSE)
    fit_B_bj <- bujar(log(df_B$T_obs), df_B$delta, x_B, learner = "linear.regression", tuning = FALSE)
    Q_A_bj <- exp(predict(fit_A_bj, newx = x_all))
    Q_B_bj <- exp(predict(fit_B_bj, newx = x_all))
    opt_bj <- ifelse(Q_A_bj > Q_B_bj, 1, 0)
    
    # --- BJ LS ---
    fit_A_bjls <- bujar(log(df_A$T_obs), df_A$delta, x_A, twin = TRUE, mstop = 1000, mstop2 = 100, cv = FALSE)
    fit_B_bjls <- bujar(log(df_B$T_obs), df_B$delta, x_B, twin = TRUE, mstop = 1000, mstop2 = 100, cv = FALSE)
    Q_A_bjls <- exp(predict(fit_A_bjls, newx = x_all))
    Q_B_bjls <- exp(predict(fit_B_bjls, newx = x_all))
    opt_bjls <- ifelse(Q_A_bjls > Q_B_bjls, 1, 0)
    
    # --- BJ Tree ---
    fit_A_bjtree <- bujar(log(df_A$T_obs), df_A$delta, x_A, learner = "tree", tuning = TRUE, degree = 2, mstop = 100)
    fit_B_bjtree <- bujar(log(df_B$T_obs), df_B$delta, x_B, learner = "tree", tuning = TRUE, degree = 2, mstop = 100)
    Q_A_bjtree <- exp(predict(fit_A_bjtree, newx = x_all))
    Q_B_bjtree <- exp(predict(fit_B_bjtree, newx = x_all))
    opt_bjtree <- ifelse(Q_A_bjtree > Q_B_bjtree, 1, 0)
    
    # --- Cox ---
    fit_A_cox <- coxph(Surv(T_obs, delta) ~ Sex + TumorSize + BMI, data = df_A)
    fit_B_cox <- coxph(Surv(T_obs, delta) ~ Sex + TumorSize + BMI, data = df_B)
    lp_A <- predict(fit_A_cox, newdata = df, type = "lp")
    lp_B <- predict(fit_B_cox, newdata = df, type = "lp")
    base_A <- basehaz(fit_A_cox, centered = FALSE)
    base_B <- basehaz(fit_B_cox, centered = FALSE)
    compute_surv <- function(lp, base) {
      sapply(lp, function(lpi) sum(diff(c(0, base$time)) * exp(-base$hazard * exp(lpi))))
    }
    Q_A_cox <- compute_surv(lp_A, base_A)
    Q_B_cox <- compute_surv(lp_B, base_B)
    opt_cox <- ifelse(Q_A_cox > Q_B_cox, 1, 0)
    
    decisions[[rep]] <- list(
      bj = opt_bj,
      bjls = opt_bjls,
      bjtree = opt_bjtree,
      cox = opt_cox
    )
  }
  
  # Average accuracy across 2 repetitions
  acc_bj_cum[sim]     <- mean((decisions[[1]]$bj == true_opts[[1]]) & (decisions[[2]]$bj == true_opts[[2]]))
  acc_bjls_cum[sim]   <- mean((decisions[[1]]$bjls == true_opts[[1]]) & (decisions[[2]]$bjls == true_opts[[2]]))
  acc_bjtree_cum[sim] <- mean((decisions[[1]]$bjtree == true_opts[[1]]) & (decisions[[2]]$bjtree == true_opts[[2]]))
  acc_cox_cum[sim]    <- mean((decisions[[1]]$cox == true_opts[[1]]) & (decisions[[2]]$cox == true_opts[[2]]))
}

# Results
list(
  BJ = summary(acc_bj_cum),
  BJLS = summary(acc_bjls_cum),
  BJTree = summary(acc_bjtree_cum),
  Cox = summary(acc_cox_cum)
)
